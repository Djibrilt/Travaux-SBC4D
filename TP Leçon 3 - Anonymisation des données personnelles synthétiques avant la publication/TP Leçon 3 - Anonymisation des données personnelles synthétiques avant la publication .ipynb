{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTIE 1 - TUTO COURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairie\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "df = pd.read_csv(\"patient-data-anonymisation-exercise.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir la liste des fields des données \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisons aussi geopandas et regardons l'emplacement physique de nos données\n",
    "\n",
    "gdf = gd.GeoDataFrame(df, crs=\"EPSG:4326\", geometry=gd.points_from_xy(df.LON, df.LAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproject\n",
    "gdf = gdf.to_crs(epsg=3857)\n",
    "ax = gdf.plot(figsize=(20, 20), alpha=0.5, edgecolor='k')\n",
    "ctx.add_basemap(ax=ax, source=ctx.providers.Stamen.TonerLite, zoom=12)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préciser les colonnes pour l'éloignement\n",
    "suppression = [\"SSN\", \"DRIVERS\", \"PASSPORT\", \"FIRST\", \"LAST\", \"MAIDEN\", \"ADDRESS\", \"ZIP\"]\n",
    "# Et les laisser tomber\n",
    "df.drop(suppression, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecrivons une class Python à exécuter pendant que nous anonymisons nos données\n",
    "\n",
    "import uuid\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class Pseudonymise:\n",
    "    \n",
    "    def __init__(self, sigma=0.001):\n",
    "        # Initialiser un dictionnaire par défaut, cela crée un élément de dictionnaire par défaut s'il n'existe pas\n",
    "        # Nous utilisons cette méthode pour garantir l'intégrité des données tout en les rendant aléatoires\n",
    "        # http://ikigomu.com/?p=28\n",
    "        self.sigma = sigma\n",
    "        self.mu = 0 # Nous voulons nous écarter de la vérité\n",
    "        # Pseudo-patient dict\n",
    "        self.pp = defaultdict(lambda: {\"uuid\":str(uuid.uuid4()),\n",
    "                                       \"lat\": np.random.normal(self.mu, self.sigma),\n",
    "                                       \"lon\": np.random.normal(self.mu, self.sigma)\n",
    "                                      })\n",
    "        \n",
    "    def create_data(self, identities):\n",
    "        \"\"\"\n",
    "        Pour chaque identité unique produire un UUID unique, et un gaussien randomisé \"LAT\" et \"LON\".\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        identities: liste des chaînes de caractères\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Chaque entrée de dict contient un enregistrement contenant un \"uuid\" et un modificateur pour \"lat\" et \"lon\".\n",
    "        \"\"\"\n",
    "        for _id in identities:\n",
    "            self.pp[_id]\n",
    "        return self.pp\n",
    "    \n",
    "    def redact(self, row):\n",
    "        \"\"\"\n",
    "        Pour une ligne donnée dans un dataframe, retournez la version pseudonymisée de \"PATIENT_ID\", \"LAT\", \"LON\".\n",
    "        \n",
    "        Parameters:\n",
    "        row : Ligne de la trame de données\n",
    "        \n",
    "        row:\n",
    "        DataFrame tranche de ligne \n",
    "        \"\"\"\n",
    "        return [\n",
    "            self.pp[row[\"PATIENT_ID\"]][\"uuid\"],\n",
    "            row[\"LAT\"] + self.pp[row[\"PATIENT_ID\"]][\"lat\"],\n",
    "            row[\"LON\"] + self.pp[row[\"PATIENT_ID\"]][\"lon\"],\n",
    "        ]\n",
    "\n",
    "p = Pseudonymise()\n",
    "pp_data = p.create_data(df[\"PATIENT_ID\"])\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html\n",
    "fields = [\"PATIENT_ID\", \"LAT\", \"LON\"]\n",
    "df[fields] = df[fields].apply(p.redact, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancons la visualisation dans GeoPandas\n",
    "\n",
    "gdf = gd.GeoDataFrame(df, crs=\"EPSG:4326\", geometry=gd.points_from_xy(df.LON, df.LAT))\n",
    "gdf = gdf.to_crs(epsg=3857)\n",
    "ax = gdf.plot(figsize=(20, 20), alpha=0.5, edgecolor='k')\n",
    "ctx.add_basemap(ax=ax, source=ctx.providers.Stamen.TonerLite, zoom=12)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARTIE 2 - L'AGGREGATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir en date \n",
    "df = df.copy()\n",
    "\n",
    "for c in [\"BIRTHDATE\"]:\n",
    "    df[c] = df[c].apply(lambda x: pd.to_datetime(x, errors=\"coerce\", dayfirst=True).date())\n",
    "\n",
    "def annee_uniquement(value):\n",
    "    return value.year\n",
    "\n",
    "df[\"BIRTHDATE\"]=df[\"BIRTHDATE\"].apply(annee_uniquement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne montrer que l'année\n",
    "\n",
    "A=df[\"BIRTHDATE\"]\n",
    "A.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agréger par chaque tranche d'age les raisons de la visite \n",
    "\n",
    "groupe1 = df.groupby([\"BIRTHDATE\", 'DESCRIPTION'])\n",
    "B = groupe1.aggregate(np.sum)\n",
    "B.drop(B.iloc[:,:],1,inplace=True)\n",
    "B.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculer pour chaque tranche d'âge le total de tous les coûts des sinistres¶\n",
    "    \n",
    "groupe2 = df.groupby([\"BIRTHDATE\", 'TOTAL_CLAIM_COST'])\n",
    "C = groupe2.aggregate(np.sum)\n",
    "C.drop(C.iloc[:,:],1,inplace=True)\n",
    "C.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculons pour chaque tranche d'âge, la médiane de tous les coûts des sinistres\n",
    "\n",
    "groupe3 = df.groupby([\"BIRTHDATE\", 'TOTAL_CLAIM_COST'])\n",
    "D = groupe3.aggregate(np.median)\n",
    "D.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
